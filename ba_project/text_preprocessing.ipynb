{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This file is used for preprocessing twitter data\n",
    "# Saving into relevant data shape and data cleaning\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from gensim.parsing.preprocessing import remove_stopwords, strip_non_alphanum\n",
    "from gensim.parsing.preprocessing import strip_numeric, strip_punctuation, strip_short\n",
    "\n",
    "# import gensim\n",
    "# print(gensim.parsing.preprocessing.STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count total token words in a DataFrame column\n",
    "def count_words(text_column):\n",
    "    tokens = 0\n",
    "    for items in text_column.iteritems():\n",
    "        n = len(items[1].split())\n",
    "        tokens += n\n",
    "    return tokens\n",
    "\n",
    "# Map POS tag to first character lemmatize() accepts\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>HashTags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is it landlord that has been struggling since ...</td>\n",
       "      <td>2020-08-09 23:55:14+00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Victorian new cases trending down as impact of...</td>\n",
       "      <td>2020-08-09 23:53:42+00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#auspol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello Monday. As Melbourne starts week two in ...</td>\n",
       "      <td>2020-08-09 23:48:01+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The ironic part is the same people patting you...</td>\n",
       "      <td>2020-08-09 23:47:48+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In several states, positive coronavirus tests ...</td>\n",
       "      <td>2020-08-09 23:46:39+00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  Is it landlord that has been struggling since ...   \n",
       "1  Victorian new cases trending down as impact of...   \n",
       "2  Hello Monday. As Melbourne starts week two in ...   \n",
       "3  The ironic part is the same people patting you...   \n",
       "4  In several states, positive coronavirus tests ...   \n",
       "\n",
       "                        Date  Retweets  Favorites Mentions HashTags  \n",
       "0  2020-08-09 23:55:14+00:00        13         47      NaN      NaN  \n",
       "1  2020-08-09 23:53:42+00:00         8         29      NaN  #auspol  \n",
       "2  2020-08-09 23:48:01+00:00         7         23      NaN      NaN  \n",
       "3  2020-08-09 23:47:48+00:00         5         76      NaN      NaN  \n",
       "4  2020-08-09 23:46:39+00:00        13         16      NaN      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing raw tweets data from csv\n",
    "\n",
    "tweets = pd.read_csv(\"tweets_raw.csv\", index_col=0)\n",
    "words_earlier = count_words(tweets[\"Text\"])\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>landlord struggling beginning lockdown source ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>victorian new cases trending impact stage lock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello monday melbourne starts week lockdown da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ironic people patting tweet probably agreeing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>states positive coronavirus tests created prob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  landlord struggling beginning lockdown source ...\n",
       "1  victorian new cases trending impact stage lock...\n",
       "2  hello monday melbourne starts week lockdown da...\n",
       "3  ironic people patting tweet probably agreeing ...\n",
       "4  states positive coronavirus tests created prob..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing links and ampersand attached text from the tweets\n",
    "tweets_text = pd.DataFrame([re.sub(r\"(?:\\@|\\&|http)\\S+\", \"\", item) for item in tweets[\"Text\"]],\n",
    "                              columns = [\"text\"])\n",
    "\n",
    "# Removing non-alphabetic and numeric characters\n",
    "tweets_text[\"text\"] = [strip_numeric(item) for item in tweets_text[\"text\"]]\n",
    "tweets_text[\"text\"] = [strip_non_alphanum(item) for item in tweets_text[\"text\"]]\n",
    "\n",
    "# Removing punctuation characters\n",
    "tweets_text[\"text\"] = [strip_punctuation(item) for item in tweets_text[\"text\"]]\n",
    "\n",
    "# Short words removal, minsize 3\n",
    "tweets_text[\"text\"] = [strip_short(item, minsize=3) for item in tweets_text[\"text\"]]\n",
    "\n",
    "# All text to lower case\n",
    "tweets_text[\"text\"] = [item.lower() for item in tweets_text[\"text\"]]\n",
    "\n",
    "# Removing the stopwords from the tweets\n",
    "tweets_text[\"text\"] = [remove_stopwords(item) for item in tweets_text[\"text\"]]\n",
    "                                   \n",
    "# Remove everything except text\n",
    "# tweets_text[\"text\"] = [re.sub(r\"[^a-zA-Z]+\", ' ', item) for item in tweets_text[\"text\"]]\n",
    "# tweets_text[\"text\"] = [re.sub(r\"[^a-zA-Z0-9]+\", ' ', item) for item in tweets_text[\"text\"]]\n",
    "\n",
    "tweets_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words before preprocessing: 15334\n",
      "Words after preprocessing: 6349\n",
      "Words removed: 8985\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>landlord</td>\n",
       "      <td>struggle</td>\n",
       "      <td>begin</td>\n",
       "      <td>lockdown</td>\n",
       "      <td>source</td>\n",
       "      <td>income</td>\n",
       "      <td>want</td>\n",
       "      <td>beg</td>\n",
       "      <td>people</td>\n",
       "      <td>well</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new</td>\n",
       "      <td>case</td>\n",
       "      <td>trend</td>\n",
       "      <td>impact</td>\n",
       "      <td>stage</td>\n",
       "      <td>lockdown</td>\n",
       "      <td>kick</td>\n",
       "      <td>thanks</td>\n",
       "      <td>stay</td>\n",
       "      <td>strong</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello</td>\n",
       "      <td>start</td>\n",
       "      <td>week</td>\n",
       "      <td>lockdown</td>\n",
       "      <td>day</td>\n",
       "      <td>million</td>\n",
       "      <td>remote</td>\n",
       "      <td>learn</td>\n",
       "      <td>middle</td>\n",
       "      <td>grade</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people</td>\n",
       "      <td>pat</td>\n",
       "      <td>tweet</td>\n",
       "      <td>probably</td>\n",
       "      <td>agree</td>\n",
       "      <td>people</td>\n",
       "      <td>protest</td>\n",
       "      <td>lockdown</td>\n",
       "      <td>end</td>\n",
       "      <td>mess</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>state</td>\n",
       "      <td>positive</td>\n",
       "      <td>test</td>\n",
       "      <td>create</td>\n",
       "      <td>problem</td>\n",
       "      <td>reopen</td>\n",
       "      <td>school</td>\n",
       "      <td>send</td>\n",
       "      <td>teacher</td>\n",
       "      <td>student</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1      2         3        4         5        6         7   \\\n",
       "0  landlord  struggle  begin  lockdown   source    income     want       beg   \n",
       "1       new      case  trend    impact    stage  lockdown     kick    thanks   \n",
       "2     hello     start   week  lockdown      day   million   remote     learn   \n",
       "3    people       pat  tweet  probably    agree    people  protest  lockdown   \n",
       "4     state  positive   test    create  problem    reopen   school      send   \n",
       "\n",
       "        8        9   ...    18    19    20    21    22    23    24    25  \\\n",
       "0   people     well  ...  None  None  None  None  None  None  None  None   \n",
       "1     stay   strong  ...  None  None  None  None  None  None  None  None   \n",
       "2   middle    grade  ...  None  None  None  None  None  None  None  None   \n",
       "3      end     mess  ...  None  None  None  None  None  None  None  None   \n",
       "4  teacher  student  ...  None  None  None  None  None  None  None  None   \n",
       "\n",
       "     26    27  \n",
       "0  None  None  \n",
       "1  None  None  \n",
       "2  None  None  \n",
       "3  None  None  \n",
       "4  None  None  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting words in the text into tokens and putting into a dataframe\n",
    "# Each row has useful words from a single tweet (like a transaction)\n",
    "\n",
    "tweets_ll = []\n",
    "words_after = 0\n",
    "lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "for items in tweets_text[\"text\"].iteritems():\n",
    "    word_list = items[1].split()\n",
    "    # Text lemmatization and removing non-dictionary words\n",
    "    word_list = [lemma.lemmatize(x, get_wordnet_pos(x)) for x in word_list]\n",
    "    word_list = [x for x in word_list if x in words or not x.isalpha()]\n",
    "    words_after += len(word_list)\n",
    "    tweets_ll.append(word_list)\n",
    "    word_list = None\n",
    "\n",
    "print(\"Words before preprocessing: {}\".format(words_earlier))\n",
    "print(\"Words after preprocessing: {}\".format(words_after))\n",
    "print(\"Words removed: {}\".format(words_earlier-words_after))\n",
    "    \n",
    "tweets_tokenized = pd.DataFrame(tweets_ll)\n",
    "tweets_tokenized.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_tokenized.to_csv(\"tweets_tokenized_py.csv\", index = False, header = True)\n",
    "tweets_tokenized.index += 1\n",
    "tweets_tokenized.to_csv(\"tweets_tokenized_r.csv\", index = True, header = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
