{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This file is used for preprocessing twitter data\n",
    "# Saving into relevant data shape and data cleaning\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from gensim.parsing.preprocessing import remove_stopwords, strip_non_alphanum\n",
    "from gensim.parsing.preprocessing import strip_numeric, strip_punctuation, strip_short\n",
    "\n",
    "# import gensim\n",
    "# print(gensim.parsing.preprocessing.STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count total token words in a DataFrame or a column\n",
    "def count_words(var):\n",
    "    if isinstance(var, pd.Series):\n",
    "        tokens = 0\n",
    "        for items in var.iteritems():\n",
    "            tokens += len(items[1].split())\n",
    "        return tokens\n",
    "    elif isinstance(var, pd.DataFrame):\n",
    "        return var.count().sum()\n",
    "    \n",
    "# Map POS tag to first character lemmatize() accepts\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "# Custom functionfor text lemmatization and removing non-dictionary words\n",
    "def lemmatize_custom(my_list, cwords):\n",
    "    start = time.time()\n",
    "    lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "    words = set(nltk.corpus.words.words())\n",
    "    \n",
    "    with open(\"behaviour_words.txt\",\"r\") as f:\n",
    "        lines = [line.strip() for line in f]\n",
    "    behaviour_words = []\n",
    "    for i in lines:\n",
    "        for ix in i.split():\n",
    "            behaviour_words.append(ix)\n",
    "    cwords = cwords + behaviour_words\n",
    "    \n",
    "    for i in cwords:\n",
    "        words.add(i)\n",
    "        \n",
    "    tweets_ll = []\n",
    "    for item in my_list:\n",
    "        word_list = item.split()\n",
    "        word_list = [lemma.lemmatize(x, get_wordnet_pos(x)) for x in word_list]\n",
    "        word_list = [x for x in word_list if x in words]\n",
    "        word_list = [x for x in word_list if x in behaviour_words]\n",
    "        tweets_ll.append(word_list)\n",
    "        word_list = None\n",
    "    end = time.time()\n",
    "    print(\"Total time taken in lemmatization: {:.2f} seconds\".format(end-start))\n",
    "    return pd.DataFrame(tweets_ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data importing from our saved csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 4750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>HashTags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>Lockdown Day 7: Banks begin loan moratorium me...</td>\n",
       "      <td>2020-04-01 00:07:13+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>It’s not a surprise that people had to get gra...</td>\n",
       "      <td>2020-04-01 00:33:33+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>bought a new phone bc I ran out of storage for...</td>\n",
       "      <td>2020-04-01 01:17:18+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>Looking forward to ending the lockdown, Britai...</td>\n",
       "      <td>2020-04-01 01:40:23+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>u know i bought stardew valley on my phone bc ...</td>\n",
       "      <td>2020-04-01 02:45:03+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "2835  Lockdown Day 7: Banks begin loan moratorium me...   \n",
       "2834  It’s not a surprise that people had to get gra...   \n",
       "495   bought a new phone bc I ran out of storage for...   \n",
       "3483  Looking forward to ending the lockdown, Britai...   \n",
       "494   u know i bought stardew valley on my phone bc ...   \n",
       "\n",
       "                           Date  Retweets  Favorites Mentions HashTags  \n",
       "2835  2020-04-01 00:07:13+00:00         0          0      NaN      NaN  \n",
       "2834  2020-04-01 00:33:33+00:00         0          1      NaN      NaN  \n",
       "495   2020-04-01 01:17:18+00:00         0          1      NaN      NaN  \n",
       "3483  2020-04-01 01:40:23+00:00         0          0      NaN      NaN  \n",
       "494   2020-04-01 02:45:03+00:00         0          0      NaN      NaN  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing raw tweets data from csv\n",
    "\n",
    "tweets = pd.read_csv(\"tweets_raw_berk.csv\", index_col=0)\n",
    "words_earlier = count_words(tweets[\"Text\"])\n",
    "print(\"Number of rows: {}\".format(tweets.shape[0]))\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lockdown day banks begin loan moratorium measu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>surprise people grants mobile pay points like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bought new phone ran storage photos bout month...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking forward ending lockdown britain german...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>know bought stardew valley phone wanted play a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  lockdown day banks begin loan moratorium measu...\n",
       "1  surprise people grants mobile pay points like ...\n",
       "2  bought new phone ran storage photos bout month...\n",
       "3  looking forward ending lockdown britain german...\n",
       "4  know bought stardew valley phone wanted play a..."
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing links and ampersand attached text from the tweets\n",
    "tweets_text = [re.sub(r\"(?:\\@|\\&|http)\\S+\", \"\", item) for item in tweets[\"Text\"]]\n",
    "\n",
    "# Removing non-alphabetic and numeric characters\n",
    "tweets_text = [strip_numeric(item) for item in tweets_text]\n",
    "tweets_text = [strip_non_alphanum(item) for item in tweets_text]\n",
    "\n",
    "# Removing punctuation characters\n",
    "tweets_text = [strip_punctuation(item) for item in tweets_text]\n",
    "\n",
    "# Short words removal, minsize 3\n",
    "tweets_text = [strip_short(item, minsize=3) for item in tweets_text]\n",
    "\n",
    "# All text to lower case\n",
    "tweets_text = [item.lower() for item in tweets_text]\n",
    "\n",
    "# Removing the stopwords from the tweets\n",
    "tweets_text = [remove_stopwords(item) for item in tweets_text]\n",
    "                                   \n",
    "# Remove everything except text\n",
    "# tweets_text[\"text\"] = [re.sub(r\"[^a-zA-Z]+\", ' ', item) for item in tweets_text[\"text\"]]\n",
    "# tweets_text[\"text\"] = [re.sub(r\"[^a-zA-Z0-9]+\", ' ', item) for item in tweets_text[\"text\"]]\n",
    "\n",
    "pd.DataFrame(tweets_text, columns=[\"Text\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding sentiment label of tweets\n",
    "with open(\"lexicon/positive.txt\", \"r\") as f:\n",
    "    positive = [line.strip() for line in f]\n",
    "with open(\"lexicon/negative.txt\", \"r\") as f:\n",
    "    negative = [line.strip() for line in f]\n",
    "\n",
    "tweets_senti = []\n",
    "for item in tweets_text:\n",
    "    word_list = item.split()\n",
    "    p = 0; n = 0; neu = 0\n",
    "    for i in word_list:\n",
    "        if i in positive:\n",
    "            p+=1\n",
    "        elif i in negative:\n",
    "            n+=1\n",
    "        else:\n",
    "            neu+=1\n",
    "    if p>=n:\n",
    "        tweets_senti.append(\"positive\")\n",
    "    elif n>p:\n",
    "        tweets_senti.append(\"negative\")\n",
    "    \n",
    "    word_list = None\n",
    "    \n",
    "sentiment_labels = pd.Series(tweets_senti, name = \"sentiment\")\n",
    "sentiment_labels.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runnning our custom lemmatization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken in lemmatization: 13.27 seconds\n"
     ]
    }
   ],
   "source": [
    "# Converting words in the text into tokens and putting into a dataframe\n",
    "# Each row has useful words from a single tweet (like a transaction)\n",
    "\n",
    "# custom_words = [\"lockdown\"]\n",
    "custom_words = []\n",
    "tweets_tokenized = lemmatize_custom(tweets_text, custom_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words before preprocessing: 188916\n",
      "Words after preprocessing: 10642\n",
      "Words removed: 178274\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pay</td>\n",
       "      <td>mobile</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mobile</td>\n",
       "      <td>pay</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bought</td>\n",
       "      <td>phone</td>\n",
       "      <td>phone</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>smartphone</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bought</td>\n",
       "      <td>phone</td>\n",
       "      <td>want</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0       1      2     3     4     5     6     7     8     9     10  \\\n",
       "0         pay  mobile   None  None  None  None  None  None  None  None  None   \n",
       "1      mobile     pay   None  None  None  None  None  None  None  None  None   \n",
       "2      bought   phone  phone  None  None  None  None  None  None  None  None   \n",
       "3  smartphone    None   None  None  None  None  None  None  None  None  None   \n",
       "4      bought   phone   want  None  None  None  None  None  None  None  None   \n",
       "\n",
       "     11  \n",
       "0  None  \n",
       "1  None  \n",
       "2  None  \n",
       "3  None  \n",
       "4  None  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_after = count_words(tweets_tokenized)\n",
    "print(\"Words before preprocessing: {}\".format(words_earlier))\n",
    "print(\"Words after preprocessing: {}\".format(words_after))\n",
    "print(\"Words removed: {}\".format(words_earlier-words_after))\n",
    "\n",
    "tweets_tokenized.dropna(how=\"all\")\n",
    "tweets_tokenized.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_tokenized.to_csv(\"tweets_tokenized_py.csv\", index = False, header = True)\n",
    "# tweets_tokenized.index += 1\n",
    "# tweets_tokenized.to_csv(\"tweets_tokenized_r.csv\", index = True, header = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
