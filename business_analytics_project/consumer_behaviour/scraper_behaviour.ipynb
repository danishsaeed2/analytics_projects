{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GetOldTweets3 as got\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_print(time_secs):\n",
    "    d = datetime.datetime(1,1,1) + datetime.timedelta(seconds = time_secs)\n",
    "    date_str = \"{}{}{}{}\".format(str(d.day-1)+\" days, \" if d.day>1 else \"\",\n",
    "                                str(d.hour)+\" hours, \" if d.hour>0 else \"\",\n",
    "                                str(d.minute)+\" min, \" if d.minute>0 else \"\",\n",
    "                                str(d.second)+\" secs\")\n",
    "    return date_str\n",
    "\n",
    "def keywords_prep_part2(behaviour_list,n):\n",
    "    \n",
    "    temp_set = set([k for i in behaviour_list for j in i for k in j.split()])\n",
    "    with open('behaviour_words.txt', 'w') as f:\n",
    "        for item in list(temp_set):\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    bwords = []\n",
    "    for item in behaviour_list:\n",
    "        activity = item.pop(0)\n",
    "        for i in item:\n",
    "            bwords.append(activity + \" \" + i)\n",
    "\n",
    "    print(\"Number of permutations: {}\".format(len(bwords)))\n",
    "    print(\"Number of max rows to be pulled: {}\".format(len(bwords)*n) \n",
    "          if n>0\n",
    "          else \"All possible tweets for each keyword will be pulled\")\n",
    "    return bwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GetOldTweets3 enabler function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(query, top_only, start_date, end_date, max_tweets):\n",
    "   \n",
    "    # specifying tweet search criteria\n",
    "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(query)\\\n",
    "                                                .setTopTweets(top_only)\\\n",
    "                                                .setSince(start_date)\\\n",
    "                                                .setUntil(end_date)\\\n",
    "                                                .setMaxTweets(max_tweets)\n",
    "    \n",
    "    # scraping tweets based on criteria\n",
    "    tweet = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "    \n",
    "    # creating list of tweets with the tweet attributes specified in the list comprehension\n",
    "    text_tweets = [[tw.text,\n",
    "                    tw.date,\n",
    "                    tw.retweets,\n",
    "                    tw.favorites,\n",
    "                    tw.mentions,\n",
    "                    tw.hashtags] for tw in tweet]\n",
    "    \n",
    "    # creating dataframe, assigning column names to list of tweets corresponding to tweet attributes\n",
    "    tweets_df = pd.DataFrame(text_tweets, \n",
    "                            columns = ['Text','Date','Retweets','Favorites','Mentions','HashTags'])\n",
    "    \n",
    "    return tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper function for custom words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scraper(queries,fixedk,limit_keyword):\n",
    "    tweets_temp = pd.DataFrame(columns = ['Text','Date','Retweets','Favorites','Mentions','HashTags'])\n",
    "    total_loop_time = 0\n",
    "    avg_loop_time = 0\n",
    "    len_queries = len(queries)\n",
    "    for i,word in enumerate(queries):\n",
    "        start = time.time()\n",
    "\n",
    "        custom_query = \" \".join(fixedk)+\" \"+word\n",
    "        tweet_out = get_tweets(custom_query,\n",
    "                                top_only = False,\n",
    "                                start_date = \"2020-04-01\",\n",
    "                                end_date = \"2020-08-01\",\n",
    "                                max_tweets = limit_keyword)\n",
    "        tweets_temp = tweets_temp.append(tweet_out, ignore_index=True)\n",
    "\n",
    "        end = time.time()\n",
    "        total_loop_time += end-start\n",
    "        avg_loop_time = total_loop_time/(i+1)\n",
    "        time_left = (avg_loop_time) * (len_queries-i)\n",
    "\n",
    "        out1 = \"{} in {}: Query \\\"{}\\\" ({:.2f} secs) (Rows: {})\".format(i,len_queries,custom_query,\n",
    "                                                                        (end-start),len(tweet_out))\n",
    "        out2 = \"ETA: {}\".format(time_print(time_left))\n",
    "        print(\"{:<80s}{:<35s}\".format(out1,out2))\n",
    "\n",
    "    print(\"\\nTotal query time: {}\".format(time_print(total_loop_time)))\n",
    "    return tweets_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Basic scrape code (not in use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Between a specific range of dates, with end date not inclusive\n",
    "# And specifying that we want a max number of tweets in max_tweets.\n",
    "\n",
    "# The main query word goes here, case insensitive\n",
    "query = \"lockdown\"\n",
    "tweets_df = get_tweets(query,\n",
    "                        top_only = False,\n",
    "                        start_date = \"2020-04-01\",\n",
    "                        end_date = \"2020-08-01\",\n",
    "                        max_tweets = 1)\n",
    "tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling for Part 2 - Behaviour analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of permutations: 36\n",
      "Number of max rows to be pulled: 144000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['watched movie',\n",
       " 'watched netflix',\n",
       " 'watched amazon prime',\n",
       " 'watched hotstar',\n",
       " 'watched youtube']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behaviour_list = []\n",
    "behaviour_list.append([\"watched\",\"movie\",\"netflix\",\"amazon prime\",\"hotstar\",\"youtube\",\"online\"])\n",
    "behaviour_list.append([\"watching\",\"movie\",\"netflix\",\"amazon prime\",\"hotstar\",\"youtube\",\"online\"])\n",
    "behaviour_list.append([\"played\",\"game\",\"xbox\",\"playstation\",\"android\",\"game online\"])\n",
    "behaviour_list.append([\"playing\",\"game\",\"xbox\",\"playstation\",\"android\",\"game online\"])\n",
    "behaviour_list.append([\"shopping\",\"flipkart\",\"amazon\",\"myntra\",\"jabong\",\"online\"])\n",
    "behaviour_list.append([\"ordered\",\"zomato\",\"swiggy\",\"food online\"])\n",
    "behaviour_list.append([\"listening\",\"music\",\"saavn\",\"spotify\",\"gaana\",\"youtube music\",\"music online\"])\n",
    "\n",
    "# Tweets for each query keyword, <1 means all possible tweets\n",
    "tweets_per_keyword = 4000\n",
    "\n",
    "behaviour_words = keywords_prep_part2(behaviour_list,tweets_per_keyword)\n",
    "behaviour_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 in 36: Query \"lockdown watched movie\" (566.27 secs) (Rows: 4000)              ETA: 5 hours, 39 min, 45 secs      \n",
      "1 in 36: Query \"lockdown watched netflix\" (776.26 secs) (Rows: 4000)            ETA: 6 hours, 31 min, 34 secs      \n",
      "2 in 36: Query \"lockdown watched amazon prime\" (75.44 secs) (Rows: 539)         ETA: 4 hours, 27 min, 50 secs      \n",
      "3 in 36: Query \"lockdown watched hotstar\" (31.51 secs) (Rows: 233)              ETA: 3 hours, 19 min, 18 secs      \n",
      "4 in 36: Query \"lockdown watched youtube\" (182.58 secs) (Rows: 1042)            ETA: 2 hours, 54 min, 5 secs       \n",
      "5 in 36: Query \"lockdown watched online\" (617.26 secs) (Rows: 4000)             ETA: 3 hours, 13 min, 41 secs      \n",
      "6 in 36: Query \"lockdown watching movie\" (54.79 secs) (Rows: 374)               ETA: 2 hours, 44 min, 34 secs      \n",
      "7 in 36: Query \"lockdown watching netflix\" (460.87 secs) (Rows: 3528)           ETA: 2 hours, 47 min, 3 secs       \n",
      "8 in 36: Query \"lockdown watching amazon prime\" (29.69 secs) (Rows: 211)        ETA: 2 hours, 24 min, 54 secs      \n",
      "9 in 36: Query \"lockdown watching hotstar\" (16.30 secs) (Rows: 109)             ETA: 2 hours, 6 min, 29 secs       \n",
      "10 in 36: Query \"lockdown watching youtube\" (463.86 secs) (Rows: 3398)          ETA: 2 hours, 9 min, 0 secs        \n",
      "11 in 36: Query \"lockdown watching online\" (156.05 secs) (Rows: 1125)           ETA: 1 hours, 59 min, 7 secs       \n",
      "12 in 36: Query \"lockdown played game\" (531.35 secs) (Rows: 4000)               ETA: 2 hours, 1 min, 54 secs       \n",
      "13 in 36: Query \"lockdown played xbox\" (17.53 secs) (Rows: 114)                 ETA: 1 hours, 48 min, 58 secs      \n",
      "14 in 36: Query \"lockdown played playstation\" (12.10 secs) (Rows: 70)           ETA: 1 hours, 37 min, 34 secs      \n",
      "15 in 36: Query \"lockdown played android\" (3.27 secs) (Rows: 4)                 ETA: 1 hours, 27 min, 23 secs      \n",
      "16 in 36: Query \"lockdown played game online\" (16.18 secs) (Rows: 104)          ETA: 1 hours, 18 min, 39 secs      \n",
      "17 in 36: Query \"lockdown playing game\" (541.49 secs) (Rows: 4000)              ETA: 1 hours, 20 min, 5 secs       \n",
      "18 in 36: Query \"lockdown playing xbox\" (41.61 secs) (Rows: 340)                ETA: 1 hours, 12 min, 32 secs      \n",
      "19 in 36: Query \"lockdown playing playstation\" (23.78 secs) (Rows: 170)         ETA: 1 hours, 5 min, 25 secs       \n",
      "20 in 36: Query \"lockdown playing android\" (9.10 secs) (Rows: 57)               ETA: 58 min, 45 secs               \n",
      "21 in 36: Query \"lockdown playing game online\" (55.49 secs) (Rows: 416)         ETA: 53 min, 12 secs               \n",
      "22 in 36: Query \"lockdown shopping flipkart\" (17.53 secs) (Rows: 116)           ETA: 47 min, 41 secs               \n",
      "23 in 36: Query \"lockdown shopping amazon\" (71.34 secs) (Rows: 500)             ETA: 43 min, 4 secs                \n",
      "24 in 36: Query \"lockdown shopping myntra\" (10.96 secs) (Rows: 77)              ETA: 38 min, 15 secs               \n",
      "25 in 36: Query \"lockdown shopping jabong\" (0.92 secs) (Rows: 0)                ETA: 33 min, 43 secs               \n",
      "26 in 36: Query \"lockdown shopping online\" (90.72 secs) (Rows: 690)             ETA: 30 min, 5 secs                \n",
      "27 in 36: Query \"lockdown ordered zomato\" (12.79 secs) (Rows: 75)               ETA: 26 min, 10 secs               \n",
      "28 in 36: Query \"lockdown ordered swiggy\" (15.02 secs) (Rows: 101)              ETA: 22 min, 32 secs               \n",
      "29 in 36: Query \"lockdown ordered food online\" (11.91 secs) (Rows: 64)          ETA: 19 min, 6 secs                \n",
      "30 in 36: Query \"lockdown listening music\" (500.71 secs) (Rows: 3881)           ETA: 17 min, 28 secs               \n",
      "31 in 36: Query \"lockdown listening saavn\" (2.22 secs) (Rows: 1)                ETA: 14 min, 6 secs                \n",
      "32 in 36: Query \"lockdown listening spotify\" (76.61 secs) (Rows: 562)           ETA: 11 min, 5 secs                \n",
      "33 in 36: Query \"lockdown listening gaana\" (3.68 secs) (Rows: 9)                ETA: 8 min, 5 secs                 \n",
      "34 in 36: Query \"lockdown listening youtube music\" (14.14 secs) (Rows: 82)      ETA: 5 min, 14 secs                \n",
      "35 in 36: Query \"lockdown listening music online\" (11.58 secs) (Rows: 65)       ETA: 2 min, 33 secs                \n",
      "\n",
      "Total query time: 1 hours, 32 min, 2 secs\n"
     ]
    }
   ],
   "source": [
    "fixed_key = [\"lockdown\"]\n",
    "tweets_behaviour = custom_scraper(behaviour_words,fixed_key,tweets_per_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 38057\n",
      "Number of rows after deleted duplicates: 33741\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>HashTags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Since the moderated lockdown, I haven’t been l...</td>\n",
       "      <td>2020-04-01 00:02:05+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so it's online and I thought I could look up t...</td>\n",
       "      <td>2020-04-01 00:03:09+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what have i been doing during this time? cooki...</td>\n",
       "      <td>2020-04-01 00:06:12+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make this stop, we need a complete lockdown...</td>\n",
       "      <td>2020-04-01 00:17:50+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’ve been listening to my music on shuffle sin...</td>\n",
       "      <td>2020-04-01 00:23:46+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  Since the moderated lockdown, I haven’t been l...   \n",
       "1  so it's online and I thought I could look up t...   \n",
       "2  what have i been doing during this time? cooki...   \n",
       "3  To make this stop, we need a complete lockdown...   \n",
       "4  I’ve been listening to my music on shuffle sin...   \n",
       "\n",
       "                       Date Retweets Favorites Mentions HashTags  \n",
       "0 2020-04-01 00:02:05+00:00        0         0                    \n",
       "1 2020-04-01 00:03:09+00:00        0         1                    \n",
       "2 2020-04-01 00:06:12+00:00        0         0                    \n",
       "3 2020-04-01 00:17:50+00:00        0         1                    \n",
       "4 2020-04-01 00:23:46+00:00        0         1                    "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sorting by date\n",
    "tweets_behaviour.sort_values(by=\"Date\", inplace=True, ascending=True)\n",
    "print(\"Number of rows: {}\".format(tweets_behaviour.shape[0]))\n",
    "tweets_behaviour.drop_duplicates(subset=[\"Text\"], inplace=True)\n",
    "tweets_behaviour.reset_index(drop=True, inplace=True)\n",
    "print(\"Number of rows after deleted duplicates: {}\".format(tweets_behaviour.shape[0]))\n",
    "\n",
    "tweets_behaviour.to_csv(\"tweets_behaviour.csv\")\n",
    "tweets_behaviour.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
